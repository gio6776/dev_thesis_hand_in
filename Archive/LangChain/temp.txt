Run(id=UUID('e9bbbdf5-891e-4793-8dda-41a4a50950c1'), name='RunnableSequence', start_time=datetime.datetime(2024, 4, 26, 9, 42, 19, 511840), run_type='chain', end_time=datetime.datetime(2024, 4, 26, 9, 42, 41, 641650), extra={'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.1.47', 'library': 'langsmith', 'platform': 'Linux-5.15.146+-x86_64-with-glibc2.31', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.11.9', 'langchain_version': '0.1.16'}, 'metadata': {}}, error=None, serialized={'graph': {'edges': [{'source': 0, 'target': 2}, {'source': 2, 'target': 1}, {'source': 0, 'target': 3}, {'source': 3, 'target': 1}, {'source': 1, 'target': 4}, {'source': 5, 'target': 6}, {'source': 4, 'target': 5}], 'nodes': [{'data': 'Parallel<input,chat_history>Input', 'id': 0, 'type': 'schema'}, {'data': 'Parallel<input,chat_history>Output', 'id': 1, 'type': 'schema'}, {'data': {'id': ['langchain_core', 'runnables', 'base', 'RunnableLambda'], 'name': 'RunnableLambda'}, 'id': 2, 'type': 'runnable'}, {'data': {'id': ['langchain_core', 'runnables', 'base', 'RunnableLambda'], 'name': 'RunnableLambda'}, 'id': 3, 'type': 'runnable'}, {'data': {'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'name': 'ChatPromptTemplate'}, 'id': 4, 'type': 'runnable'}, {'data': {'id': ['langchain', 'chat_models', 'openai', 'ChatOpenAI'], 'name': 'ChatOpenAI'}, 'id': 5, 'type': 'runnable'}, {'data': 'ChatOpenAIOutput', 'id': 6, 'type': 'schema'}]}, 'id': ['langchain', 'schema', 'runnable', 'RunnableSequence'], 'kwargs': {'first': {'graph': {'edges': [{'source': 0, 'target': 2}, {'source': 2, 'target': 1}, {'source': 0, 'target': 3}, {'source': 3, 'target': 1}], 'nodes': [{'data': 'Parallel<input,chat_history>Input', 'id': 0, 'type': 'schema'}, {'data': 'Parallel<input,chat_history>Output', 'id': 1, 'type': 'schema'}, {'data': {'id': ['langchain_core', 'runnables', 'base', 'RunnableLambda'], 'name': 'RunnableLambda'}, 'id': 2, 'type': 'runnable'}, {'data': {'id': ['langchain_core', 'runnables', 'base', 'RunnableLambda'], 'name': 'RunnableLambda'}, 'id': 3, 'type': 'runnable'}]}, 'id': ['langchain', 'schema', 'runnable', 'RunnableParallel'], 'kwargs': {'steps': {'chat_history': {'id': ['langchain_core', 'runnables', 'base', 'RunnableLambda'], 'lc': 1, 'repr': 'RunnableLambda(...)', 'type': 'not_implemented'}, 'input': {'id': ['langchain_core', 'runnables', 'base', 'RunnableLambda'], 'lc': 1, 'repr': 'RunnableLambda(...)', 'type': 'not_implemented'}}}, 'lc': 1, 'name': 'RunnableParallel<input,chat_history>', 'type': 'constructor'}, 'last': {'graph': {'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}], 'nodes': [{'data': 'ChatOpenAIInput', 'id': 0, 'type': 'schema'}, {'data': {'id': ['langchain', 'chat_models', 'openai', 'ChatOpenAI'], 'name': 'ChatOpenAI'}, 'id': 1, 'type': 'runnable'}, {'data': 'ChatOpenAIOutput', 'id': 2, 'type': 'schema'}]}, 'id': ['langchain', 'chat_models', 'openai', 'ChatOpenAI'], 'kwargs': {'model': 'gpt-4-turbo-preview', 'openai_api_key': {'id': ['OPENAI_API_KEY'], 'lc': 1, 'type': 'secret'}, 'temperature': 0.0}, 'lc': 1, 'name': 'ChatOpenAI', 'type': 'constructor'}, 'middle': [{'graph': {'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}], 'nodes': [{'data': 'PromptInput', 'id': 0, 'type': 'schema'}, {'data': {'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'name': 'ChatPromptTemplate'}, 'id': 1, 'type': 'runnable'}, {'data': 'ChatPromptTemplateOutput', 'id': 2, 'type': 'schema'}]}, 'id': ['langchain', 'prompts', 'chat', 'ChatPromptTemplate'], 'kwargs': {'input_variables': ['chat_history', 'input'], 'messages': [{'id': ['langchain', 'prompts', 'chat', 'SystemMessagePromptTemplate'], 'kwargs': {'prompt': {'graph': {'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}], 'nodes': [{'data': 'PromptInput', 'id': 0, 'type': 'schema'}, {'data': {'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'name': 'PromptTemplate'}, 'id': 1, 'type': 'runnable'}, {'data': 'PromptTemplateOutput', 'id': 2, 'type': 'schema'}]}, 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': [], 'partial_variables': {}, 'template': 'You are an experienced SQL Developer, who is capable of tranlasting natural language into SQL code in Google Big Query Syntax. You job is to understand the Table Schema and user questions and produce a robust SQL query.\n\nHere\'s the table schema for Amazon Orders (danish-endurance-analytics.nl2sql.amazon_orders):\ndanish-endurance-analytics.nl2sql.amazon_orders(\'order_id\', \'purchase_date\', \'buyer_email\', \'market\', \'child_asin\', \'e_conomic_number\', \'product_marketing_category\', \'product_name\', \'product_pack\', \'product_and_pack\', \'product_category\', \'product_type\', \'product_size\', \'product_colour\', \'gross_sales\', \'units_sold\')\n\nGuidelines:\n- If the questions is not a business question directly related to the table schema, please simply return to the user "Your question didn\'t produce any results. Please, try another question."\n- When generating the SQL query, you must return the SQL query only, without explanation. If the user requires an explanation, they can ask for it.', 'template_format': 'f-string'}, 'lc': 1, 'name': 'PromptTemplate', 'type': 'constructor'}}, 'lc': 1, 'type': 'constructor'}, {'id': ['langchain', 'prompts', 'chat', 'MessagesPlaceholder'], 'kwargs': {'optional': False, 'variable_name': 'chat_history'}, 'lc': 1, 'type': 'constructor'}, {'id': ['langchain', 'prompts', 'chat', 'HumanMessagePromptTemplate'], 'kwargs': {'prompt': {'graph': {'edges': [{'source': 0, 'target': 1}, {'source': 1, 'target': 2}], 'nodes': [{'data': 'PromptInput', 'id': 0, 'type': 'schema'}, {'data': {'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'name': 'PromptTemplate'}, 'id': 1, 'type': 'runnable'}, {'data': 'PromptTemplateOutput', 'id': 2, 'type': 'schema'}]}, 'id': ['langchain', 'prompts', 'prompt', 'PromptTemplate'], 'kwargs': {'input_variables': ['input'], 'partial_variables': {}, 'template': '{input}', 'template_format': 'f-string'}, 'lc': 1, 'name': 'PromptTemplate', 'type': 'constructor'}}, 'lc': 1, 'type': 'constructor'}], 'partial_variables': {}}, 'lc': 1, 'name': 'ChatPromptTemplate', 'type': 'constructor'}], 'name': None}, 'lc': 1, 'name': 'RunnableSequence', 'type': 'constructor'}, events=[{'name': 'start', 'time': '2024-04-26T09:42:19.511840+00:00'}, {'name': 'end', 'time': '2024-04-26T09:42:41.641650+00:00'}], inputs={'input': 'What about the last two weeks specifically?'}, outputs={'output': {'content': '```sql\nWITH weekly_sales AS (\n  SELECT\n    market,\n    EXTRACT(WEEK FROM purchase_date) AS week_number,\n    EXTRACT(YEAR FROM purchase_date) AS year,\n    SUM(units_sold) AS units_sold\n  FROM\n    danish-endurance-analytics.nl2sql.amazon_orders\n  GROUP BY\n    market,\n    week_number,\n    year\n),\nrecent_weeks AS (\n  SELECT\n    market,\n    week_number,\n    year,\n    units_sold,\n    RANK() OVER(PARTITION BY market ORDER BY year DESC, week_number DESC) AS rank\n  FROM\n    weekly_sales\n),\nlast_two_weeks AS (\n  SELECT\n    market,\n    SUM(units_sold) AS units_sold\n  FROM\n    recent_weeks\n  WHERE\n    rank <= 2\n  GROUP BY\n    market\n),\nweek_over_week_growth AS (\n  SELECT\n    a.market,\n    ((b.units_sold - a.units_sold) / a.units_sold) * 100 AS growth_percentage\n  FROM\n    (SELECT * FROM last_two_weeks WHERE rank = 2) a\n  JOIN\n    (SELECT * FROM last_two_weeks WHERE rank = 1) b ON a.market = b.market\n)\nSELECT\n  market,\n  MAX(growth_percentage) AS max_growth_percentage\nFROM\n  week_over_week_growth\nGROUP BY\n  market\nORDER BY\n  max_growth_percentage DESC\nLIMIT\n  1;\n```', 'additional_kwargs': {}, 'response_metadata': {'token_usage': {'completion_tokens': 304, 'prompt_tokens': 532, 'total_tokens': 836}, 'model_name': 'gpt-4-turbo-preview', 'system_fingerprint': 'fp_d65ac1064c', 'finish_reason': 'stop', 'logprobs': None}, 'type': 'ai', 'id': 'run-a2844e77-67fe-4ffc-8f01-789897cf9ee4-0', 'example': False, 'tool_calls': [], 'invalid_tool_calls': []}}, reference_example_id=None, parent_run_id=None, tags=['Streamlit Chat'], session_id=UUID('2c136e79-67eb-4e62-80b5-765e142ec761'), child_run_ids=[UUID('87b51174-b76d-4a88-98b7-6aa3d1d05d2e'), UUID('5b09f672-b96b-4a21-bdb0-dc8f843e9b1e'), UUID('a1cfdce7-e32e-4aed-9847-029f56a7d582'), UUID('bbf55bd5-0a5f-4658-bfaf-1b0eb31e8983'), UUID('a2844e77-67fe-4ffc-8f01-789897cf9ee4')], child_runs=None, feedback_stats={'thumbs ðŸ‘Ž': {'n': 1, 'avg': 0.0, 'show_feedback_arrow': False}}, app_path='/o/8a8e894c-27b6-5b23-b58b-27a3c3e4e326/projects/p/2c136e79-67eb-4e62-80b5-765e142ec761/r/e9bbbdf5-891e-4793-8dda-41a4a50950c1?trace_id=e9bbbdf5-891e-4793-8dda-41a4a50950c1&start_time=2024-04-26T09:42:19.511840', manifest_id=None, status='success', prompt_tokens=532, completion_tokens=304, total_tokens=836, first_token_time=None, parent_run_ids=[], trace_id=UUID('e9bbbdf5-891e-4793-8dda-41a4a50950c1'), dotted_order='20240426T094219511840Ze9bbbdf5-891e-4793-8dda-41a4a50950c1')